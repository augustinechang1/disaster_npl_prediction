{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from utils import pad_sents\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>ProcessedText_BERT</th>\n",
       "      <th>ProcessedText_BERTbase_length</th>\n",
       "      <th>ProcessedText_BERTlarge_length</th>\n",
       "      <th>InformationType_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>our deeds are the reason of this # earthquake ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] our deeds are the reason of this # earth...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] forest fire near la ronge sask . canada</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>all residents asked to ' shelter in place ' ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] all residents asked to ' shelter in plac...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13 , 000 people receive # wildfires evacuation...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] 13 , 000 people receive # wildfires evac...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>just got sent this photo from ruby # alaska as...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] just got sent this photo from ruby # ala...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>5374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  our deeds are the reason of this # earthquake ...       1   \n",
       "1           1            forest fire near la ronge sask . canada       1   \n",
       "2           2  all residents asked to ' shelter in place ' ar...       1   \n",
       "3           3  13 , 000 people receive # wildfires evacuation...       1   \n",
       "4           4  just got sent this photo from ruby # alaska as...       1   \n",
       "\n",
       "                                  ProcessedText_BERT  \\\n",
       "0  [CLS] our deeds are the reason of this # earth...   \n",
       "1      [CLS] forest fire near la ronge sask . canada   \n",
       "2  [CLS] all residents asked to ' shelter in plac...   \n",
       "3  [CLS] 13 , 000 people receive # wildfires evac...   \n",
       "4  [CLS] just got sent this photo from ruby # ala...   \n",
       "\n",
       "   ProcessedText_BERTbase_length  ProcessedText_BERTlarge_length  \\\n",
       "0                             15                              15   \n",
       "1                             11                              11   \n",
       "2                             26                              26   \n",
       "3                             13                              13   \n",
       "4                             21                              21   \n",
       "\n",
       "   InformationType_label  \n",
       "0                   5759  \n",
       "1                    801  \n",
       "2                   5781  \n",
       "3                   3882  \n",
       "4                   5374  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [CLS] our deeds are the reason of this # earth...\n",
       "1           [CLS] forest fire near la ronge sask . canada\n",
       "2       [CLS] all residents asked to ' shelter in plac...\n",
       "3       [CLS] 13 , 000 people receive # wildfires evac...\n",
       "4       [CLS] just got sent this photo from ruby # ala...\n",
       "5       [CLS] # rockyfire update => california hwy . 2...\n",
       "6       [CLS] # flood # disaster heavy rain causes fla...\n",
       "7       [CLS] i ' m on top of the hill and i can see a...\n",
       "8       [CLS] there ' s an emergency evacuation happen...\n",
       "9       [CLS] i ' m afraid that the tornado is coming ...\n",
       "10      [CLS] three people died from the heat wave so far\n",
       "11      [CLS] haha south tampa is getting flooded hah ...\n",
       "12      [CLS] # raining # flooding # florida # tampaba...\n",
       "13        [CLS] # flood in bago myanmar # we arrived bago\n",
       "14      [CLS] damage to school bus on 80 in multi car ...\n",
       "15                                [CLS] what ' s up man ?\n",
       "16                                [CLS] my car is so fast\n",
       "17                    [CLS] what a goooooooaaaaaal !!!!!!\n",
       "18                          [CLS] this is ridiculous ....\n",
       "19                                [CLS] london is cool ;)\n",
       "20                           [CLS] what a wonderful day !\n",
       "21               [CLS] no way ... i can ' t eat that shit\n",
       "22                           [CLS] was in nyc last week !\n",
       "23                              [CLS] do you like pasta ?\n",
       "24                       [CLS]  wholesale markets ablaze \n",
       "25      [CLS] we always try to bring the heavy . # met...\n",
       "26      [CLS] # africanbaze : breaking news : nigeria ...\n",
       "27              [CLS] crying out for more ! set me ablaze\n",
       "28      [CLS] on plus side look at the sky last night ...\n",
       "29      [CLS]  # mufc they ' ve built so much hype aro...\n",
       "                              ...                        \n",
       "6841    [CLS] had an awesome time gettin wrecked at bo...\n",
       "6842     [CLS] cramer : 3 words that wrecked dis stock - \n",
       "6843                  [CLS] on the bright side i wrecked \n",
       "6844                    [CLS] he just wrecked all of you \n",
       "6845    [CLS]  ... he ' s gone . you can relax . i tho...\n",
       "6846                       [CLS]   and i wrecked you both\n",
       "6847    [CLS] three days off from work and they ' ve p...\n",
       "6848    [CLS] # fx # forex # trading cramer : iger ' s...\n",
       "6849    [CLS]  great atmosphere at the british lion gi...\n",
       "6850    [CLS] cramer : iger ' s 3 words that wrecked d...\n",
       "6851    [CLS] these boxes are ready to explode ! explo...\n",
       "6852    [CLS] calgary police flood road closures in ca...\n",
       "6853    [CLS] # sismo detectado # japì_n 15 : 41 : 07 ...\n",
       "6854    [CLS] breaking : # isis claims responsibility ...\n",
       "6855    [CLS] severe weather bulletin no . 5 for : typ...\n",
       "6856    [CLS] heat wave warning aa ? ayyo dei . just w...\n",
       "6857    [CLS] an is group suicide bomber detonated an ...\n",
       "6858    [CLS] i just heard a really loud bang and ever...\n",
       "6859    [CLS] a gas thing just exploded and i heard sc...\n",
       "6860    [CLS] nws : flash flood warning continued for ...\n",
       "6861    [CLS]  # nws issues severe # thunderstorm warn...\n",
       "6862    [CLS] #??? #?? #??? #??? mh370 : aircraft debr...\n",
       "6863    [CLS] father - of - three lost control of car ...\n",
       "6864    [CLS] 1 . 3 # earthquake in 9km ssw of anza ca...\n",
       "6865    [CLS] # breaking # la refugio oil spill may ha...\n",
       "6866    [CLS] a siren just went off and it wasn ' t th...\n",
       "6867    [CLS] officials say a quarantine is in place a...\n",
       "6868    [CLS] # worldnews fallen powerlines on g : lin...\n",
       "6869    [CLS] on the flip side i ' m at walmart and th...\n",
       "6870    [CLS] suicide bomber kills 15 in saudi securit...\n",
       "Name: ProcessedText_BERT, Length: 6871, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProcessedText_BERT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from utils import pad_sents\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = [tokenizer.tokenize(sent) for sent in list(df['ProcessedText_BERT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_lengths = [len(tokens) for tokens in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
    "    @param sents (list[list[int]]): list of sentences, where each sentence\n",
    "                                    is represented as a list of words\n",
    "    @param pad_token (int): padding token\n",
    "    @returns sents_padded (list[list[int]]): list of sentences where sentences shorter\n",
    "        than the max length sentence are padded out with the pad_token, such that\n",
    "        each sentences in the batch now has equal length.\n",
    "        Output shape: (batch_size, max_sentence_length)\n",
    "    \"\"\"\n",
    "    sents_padded = []\n",
    "\n",
    "    max_len = max(len(s) for s in sents)\n",
    "    batch_size = len(sents)\n",
    "\n",
    "    for s in sents:\n",
    "        padded = [pad_token] * max_len\n",
    "        padded[:len(s)] = s\n",
    "        sents_padded.append(padded)\n",
    "\n",
    "    return sents_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list_padded = pad_sents(tokens_list, '[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_lengths = torch.tensor(sents_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "for tokens in tokens_list_padded:\n",
    "    mask = [0 if token=='[PAD]' else 1 for token in tokens]\n",
    "    masks.append(mask)\n",
    "    \n",
    "masks_tensor = torch.tensor(masks, dtype=torch.long)\n",
    "tokens_id_list = [tokenizer.convert_tokens_to_ids(tokens) for tokens in tokens_list_padded]\n",
    "sents_tensor = torch.tensor(tokens_id_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [06:18<00:00, 1077568.71B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "pre_softmax = bert(input_ids= sents_tensor, attention_mask= masks_tensor)\n",
    "\n",
    "# input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "# labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "# outputs = model(input_ids, labels=labels)\n",
    "# loss, logits = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
